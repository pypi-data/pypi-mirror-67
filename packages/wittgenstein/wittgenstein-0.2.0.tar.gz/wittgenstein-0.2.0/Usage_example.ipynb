{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage example on congress dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These examples use the RIPPER algorithm. IREP usage is similar, with only slight hyperparameter differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wittgenstein as lw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/house-votes-84.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split our data into train-test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a ruleset classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RIPPER(verbosity=0, random_state=42, dl_allowance=64, prune_size=0.33, max_total_conds=None, k=2, n_discretize_bins=10, max_rules=None, max_rule_conds=None)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ripper_clf = lw.RIPPER(random_state=42)\n",
    "ripper_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the ruleset classifier on the trainset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Ruleset [physician-fee-freeze=n] V [adoption-of-the-budget-resolution=y^anti-satellite-test-ban=n^immigration=n]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ripper_clf.fit(train, class_feat='Party', pos_class='democrat')\n",
    "ripper_clf.ruleset_ # Access underlying model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit method is flexible and can be called in various ways, including with train_x and train_y, or with numpy arrays.  \n",
    "\n",
    "Unlike dataframes, arrays don't have feature names..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Ruleset [3=n] V [10=y^2=y^6=n] V [2=?^0=y]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = train.drop('Party', axis=1), train['Party']\n",
    "X_array, y_array = X_train.values, y_train.values\n",
    "ripper_clf.fit(X_array, y_array, pos_class='democrat')\n",
    "ripper_clf.ruleset_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can pass them in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Ruleset [physician-fee-freeze=n] V [synfuels-corporation-cutback=y^adoption-of-the-budget-resolution=y^anti-satellite-test-ban=n] V [adoption-of-the-budget-resolution=?^Handicapped-infants=y]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_array, y_arry = train.drop('Party', axis=1).values, train['Party'].values\n",
    "ripper_clf.fit(X_array, y_arry, \n",
    "               pos_class='democrat', class_feat='Party', \n",
    "               feature_names=df.columns[1:])\n",
    "ripper_clf.ruleset_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can force a simpler ruleset using max_rules, max_total_conds, or max_rule_conds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Ruleset [physician-fee-freeze=n] V [synfuels-corporation-cutback=y^physician-fee-freeze=?]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ripper_clf = lw.RIPPER(max_rules=2, random_state=1)\n",
    "ripper_clf.fit(train, class_feat='Party', pos_class='democrat')\n",
    "ripper_clf.ruleset_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verbosity allows us to view training steps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GREW INITIAL RULESET:\n",
      "[[physician-fee-freeze=n] V\n",
      "[synfuels-corporation-cutback=y] V\n",
      "[superfund-right-to-sue=?^export-administration-act-south-africa=y] V\n",
      "[adoption-of-the-budget-resolution=y^anti-satellite-test-ban=n^immigration=n]]\n",
      "\n",
      "optimization run 1 of 2\n",
      "\n",
      "OPTIMIZED RULESET:\n",
      "[[physician-fee-freeze=n] V\n",
      "[synfuels-corporation-cutback=y] V\n",
      "[superfund-right-to-sue=?^export-administration-act-south-africa=y] V\n",
      "[adoption-of-the-budget-resolution=y^anti-satellite-test-ban=n^immigration=n]]\n",
      "\n",
      "No changes were made. Halting optimization.\n",
      "GREW FINAL RULES\n",
      "[[physician-fee-freeze=n] V\n",
      "[synfuels-corporation-cutback=y] V\n",
      "[superfund-right-to-sue=?^export-administration-act-south-africa=y] V\n",
      "[adoption-of-the-budget-resolution=y^anti-satellite-test-ban=n^immigration=n] V\n",
      "[physician-fee-freeze=n] V\n",
      "[synfuels-corporation-cutback=y] V\n",
      "[superfund-right-to-sue=?^export-administration-act-south-africa=y] V\n",
      "[adoption-of-the-budget-resolution=y^anti-satellite-test-ban=n^immigration=n]]\n",
      "\n",
      "FINAL RULESET:\n",
      "[[physician-fee-freeze=n] V\n",
      "[adoption-of-the-budget-resolution=y^anti-satellite-test-ban=n^immigration=n]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Ruleset [physician-fee-freeze=n] V [adoption-of-the-budget-resolution=y^anti-satellite-test-ban=n^immigration=n]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ripper_clf = lw.RIPPER(random_state=42, verbosity=1) # Scale of 0-5\n",
    "ripper_clf.fit(train, class_feat='Party', pos_class='democrat')\n",
    "ripper_clf.ruleset_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some sklearn methods are supported. Cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95454545, 0.90769231, 0.89230769, 0.92307692, 0.90769231])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Dummify our data to make sklearn happy\n",
    "X_train = pd.get_dummies(X_train, columns=X_train.select_dtypes('object').columns)\n",
    "y_train = y_train.map(lambda x: 1 if x=='democrat' else 0)\n",
    "\n",
    "ripper_clf = lw.RIPPER(random_state=42)\n",
    "cross_val_score(ripper_clf, X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid-search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': 1, 'prune_size': 0.33}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\"prune_size\": [0.1, 0.25, 0.33, 0.5], \"k\": [1, 2]}\n",
    "grid = GridSearchCV(estimator=ripper_clf, param_grid=param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "nb = GaussianNB()\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "estimators = [(\"rip\", ripper_clf), (\"tree\", tree), (\"nb\", nb)]\n",
    "ensemble_clf = StackingClassifier(\n",
    "  estimators=estimators, final_estimator=LogisticRegression()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good is our model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.908256880733945"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.drop('Party', axis=1)\n",
    "y_test = test['Party']\n",
    "ripper_clf = lw.RIPPER(random_state=42)\n",
    "ripper_clf.fit(train, class_feat='Party', pos_class='democrat')\n",
    "ripper_clf.score(X_test, y_test) # Default metric is accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also score it on custom metrics, including sklearn's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 1.0\n",
      "recall: 0.855072463768116\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision = ripper_clf.score(X_test, y_test, precision_score)\n",
    "recall = ripper_clf.score(X_test, y_test, recall_score)\n",
    "print(f'precision: {precision}')\n",
    "print(f'recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make predictions, use the predict method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True, True, True, False, False, False, True, False, True]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ripper_clf.predict(X_test.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For predicted probabilities, use predict_proba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75903614, 0.24096386],\n",
       "       [0.01086957, 0.98913043],\n",
       "       [0.01086957, 0.98913043],\n",
       "       [0.01086957, 0.98913043],\n",
       "       [0.75903614, 0.24096386],\n",
       "       [0.75903614, 0.24096386],\n",
       "       [0.75903614, 0.24096386],\n",
       "       [0.01086957, 0.98913043],\n",
       "       [0.75903614, 0.24096386],\n",
       "       [0.01086957, 0.98913043]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ripper_clf.predict_proba(X_test.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also ask our model to give us the reasons for its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([False, False, True, False, True],\n",
       " [[],\n",
       "  [],\n",
       "  [<Rule [physician-fee-freeze=n]>],\n",
       "  [],\n",
       "  [<Rule [physician-fee-freeze=n]>]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ripper_clf.predict(X_test.tail(), give_reasons=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
