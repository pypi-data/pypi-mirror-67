{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost \n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe, space_eval\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression, RFE\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from vf_portalytics.model import PredictionModel\n",
    "from vf_portalytics.tool import squared_error_objective_with_weighting, get_categorical_features\n",
    "from vf_portalytics.transformers import get_transformer\n",
    "from vf_portalytics.multi_model import MultiModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_dataset(n_samples, n_features, n_informative, **kwargs):\n",
    "    x, y = make_regression(\n",
    "        n_samples=n_samples, \n",
    "        n_features=n_features,\n",
    "        noise=0.5,\n",
    "        n_informative=n_informative, \n",
    "        random_state=0\n",
    "    )\n",
    "    x = pd.DataFrame(x)\n",
    "    \n",
    "    x.columns = ['feature_' + str(i) for i in range(n_features)]\n",
    "    x = x.assign(**kwargs)\n",
    "    return x, pd.Series(y, name='target')\n",
    "\n",
    "\n",
    "# Generate data for 4 different categories\n",
    "# different #samples for each category but the same #features since they belong to the same dataset\n",
    "n_features = 20\n",
    "x1, y1 = make_dataset(n_samples=100, n_features=n_features, n_informative=10, category='A')\n",
    "x2, y2 = make_dataset(n_samples=150, n_features=n_features, n_informative=8, category='B')\n",
    "x3, y3 = make_dataset(n_samples=80, n_features=n_features, n_informative=7, category='C')\n",
    "x4, y4 = make_dataset(n_samples=120, n_features=n_features, n_informative=12, category='D')\n",
    "\n",
    "# combine into one dataset\n",
    "total_x = pd.concat([x1, x2, x3, x4], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "total_y = pd.concat([y1, y2, y3, y4], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "# make two random features categorical\n",
    "labels = ['g1', 'g2', 'g3']\n",
    "bins = [[],[]]\n",
    "for i in range(2):\n",
    "    bins[i] = [-np.inf, \n",
    "               total_x['feature_' + str(i)].mean() - total_x['feature_' + str(i)].std(), \n",
    "               total_x['feature_' + str(i)].mean() + total_x['feature_' + str(i)].std(), \n",
    "               total_x['feature_' + str(i)].max()]\n",
    "total_x['feature_0'] = pd.cut(total_x['feature_0'], bins=bins[0], labels=labels).astype('object')\n",
    "total_x['feature_1'] = pd.cut(total_x['feature_1'], bins=bins[1], labels=labels).astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Declare group parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C', 'D'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare basic parameters\n",
    "target = 'target'\n",
    "cat_feature = 'category'\n",
    "feature_col_list = total_x.columns.drop(cat_feature)\n",
    "\n",
    "clusters = total_x[cat_feature].unique()\n",
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "train_index, test_index = train_test_split(total_x.index, test_size=0.33, random_state=5)\n",
    "train_x, train_y = total_x.loc[train_index, :], total_y.loc[train_index]\n",
    "test_x, test_y = total_x.loc[test_index, :], total_y.loc[test_index]\n",
    "\n",
    "del x1, x2, x3, x4\n",
    "del y1, y2, y3, y4\n",
    "del total_x, total_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_selection(df_X, df_Y, features_len=1, step=1, max_features=20):\n",
    "\n",
    "    if features_len > max_features:\n",
    "        features_len = max_features\n",
    "        \n",
    "    # we fit with a lighter but representative model\n",
    "    model=xgboost.XGBRegressor(\n",
    "        max_depth=5,\n",
    "        n_estimators=50,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        n_jobs=6,\n",
    "        objective = partial(squared_error_objective_with_weighting, under_predict_weight=2.0), \n",
    "        seed=6789,\n",
    "        silent=True\n",
    "    )\n",
    "    # Turn textual columns and booleans into classes\n",
    "    transformer = get_transformer('OrdinalEncoder')\n",
    "    transformer.cols = get_categorical_features(data=df_X)\n",
    "    df_X = transformer.fit_transform(df_X)\n",
    "    \n",
    "    # create the RFE model and select the attributes\n",
    "    rfe = RFE(model,  n_features_to_select=features_len, step=step)\n",
    "    rfe = rfe.fit(df_X, df_Y)\n",
    "    return rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for Feature Ranking in A...\n",
      "Searching for Feature Ranking in B...\n",
      "Searching for Feature Ranking in C...\n",
      "Searching for Feature Ranking in D...\n"
     ]
    }
   ],
   "source": [
    "# Set your parameters; please be aware that mutual_info_regression can be very resource intensive\n",
    "max_features = train_x.shape[1]\n",
    "features_len = 1  # max number of columns: 'all' or a number\n",
    "step = 1  # x features to be dropped each step\n",
    "\n",
    "groups = train_x.groupby(cat_feature)\n",
    "feature_importances = {}\n",
    "for gp_key, x_group in groups:\n",
    "    print('Searching for Feature Ranking in ' + gp_key + '...')\n",
    "    x_group = x_group.drop(cat_feature, axis=1)\n",
    "    y_group = train_y.loc[x_group.index]\n",
    "    # find best parameters for each model-group\n",
    "    feature_importances[gp_key] = feature_selection(x_group, y_group, \n",
    "                                                    features_len=1, step=1, max_features=max_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Check The Ranking and manually decide which Features to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features ordered by importance for each group: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>feature_11</td>\n",
       "      <td>feature_13</td>\n",
       "      <td>feature_17</td>\n",
       "      <td>feature_8</td>\n",
       "      <td>feature_7</td>\n",
       "      <td>feature_18</td>\n",
       "      <td>feature_10</td>\n",
       "      <td>feature_12</td>\n",
       "      <td>feature_6</td>\n",
       "      <td>feature_14</td>\n",
       "      <td>feature_16</td>\n",
       "      <td>feature_19</td>\n",
       "      <td>feature_15</td>\n",
       "      <td>feature_9</td>\n",
       "      <td>feature_5</td>\n",
       "      <td>feature_4</td>\n",
       "      <td>feature_3</td>\n",
       "      <td>feature_2</td>\n",
       "      <td>feature_1</td>\n",
       "      <td>feature_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>feature_16</td>\n",
       "      <td>feature_19</td>\n",
       "      <td>feature_11</td>\n",
       "      <td>feature_2</td>\n",
       "      <td>feature_12</td>\n",
       "      <td>feature_6</td>\n",
       "      <td>feature_15</td>\n",
       "      <td>feature_7</td>\n",
       "      <td>feature_13</td>\n",
       "      <td>feature_17</td>\n",
       "      <td>feature_9</td>\n",
       "      <td>feature_3</td>\n",
       "      <td>feature_8</td>\n",
       "      <td>feature_10</td>\n",
       "      <td>feature_14</td>\n",
       "      <td>feature_4</td>\n",
       "      <td>feature_5</td>\n",
       "      <td>feature_0</td>\n",
       "      <td>feature_1</td>\n",
       "      <td>feature_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>feature_8</td>\n",
       "      <td>feature_18</td>\n",
       "      <td>feature_13</td>\n",
       "      <td>feature_12</td>\n",
       "      <td>feature_6</td>\n",
       "      <td>feature_4</td>\n",
       "      <td>feature_3</td>\n",
       "      <td>feature_17</td>\n",
       "      <td>feature_16</td>\n",
       "      <td>feature_15</td>\n",
       "      <td>feature_11</td>\n",
       "      <td>feature_10</td>\n",
       "      <td>feature_9</td>\n",
       "      <td>feature_5</td>\n",
       "      <td>feature_7</td>\n",
       "      <td>feature_2</td>\n",
       "      <td>feature_19</td>\n",
       "      <td>feature_0</td>\n",
       "      <td>feature_14</td>\n",
       "      <td>feature_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>feature_18</td>\n",
       "      <td>feature_14</td>\n",
       "      <td>feature_17</td>\n",
       "      <td>feature_10</td>\n",
       "      <td>feature_5</td>\n",
       "      <td>feature_13</td>\n",
       "      <td>feature_8</td>\n",
       "      <td>feature_3</td>\n",
       "      <td>feature_9</td>\n",
       "      <td>feature_4</td>\n",
       "      <td>feature_11</td>\n",
       "      <td>feature_16</td>\n",
       "      <td>feature_19</td>\n",
       "      <td>feature_12</td>\n",
       "      <td>feature_2</td>\n",
       "      <td>feature_7</td>\n",
       "      <td>feature_15</td>\n",
       "      <td>feature_6</td>\n",
       "      <td>feature_1</td>\n",
       "      <td>feature_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1           2           3           4           5  \\\n",
       "A  feature_11  feature_13  feature_17   feature_8   feature_7  feature_18   \n",
       "B  feature_16  feature_19  feature_11   feature_2  feature_12   feature_6   \n",
       "C   feature_8  feature_18  feature_13  feature_12   feature_6   feature_4   \n",
       "D  feature_18  feature_14  feature_17  feature_10   feature_5  feature_13   \n",
       "\n",
       "            6           7           8           9          10          11  \\\n",
       "A  feature_10  feature_12   feature_6  feature_14  feature_16  feature_19   \n",
       "B  feature_15   feature_7  feature_13  feature_17   feature_9   feature_3   \n",
       "C   feature_3  feature_17  feature_16  feature_15  feature_11  feature_10   \n",
       "D   feature_8   feature_3   feature_9   feature_4  feature_11  feature_16   \n",
       "\n",
       "           12          13          14         15          16         17  \\\n",
       "A  feature_15   feature_9   feature_5  feature_4   feature_3  feature_2   \n",
       "B   feature_8  feature_10  feature_14  feature_4   feature_5  feature_0   \n",
       "C   feature_9   feature_5   feature_7  feature_2  feature_19  feature_0   \n",
       "D  feature_19  feature_12   feature_2  feature_7  feature_15  feature_6   \n",
       "\n",
       "           18          19  \n",
       "A   feature_1   feature_0  \n",
       "B   feature_1  feature_18  \n",
       "C  feature_14   feature_1  \n",
       "D   feature_1   feature_0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The features ordered by importance for each group: \\n')\n",
    "ordered_feautures = []\n",
    "for cluster in clusters:\n",
    "    elements = sorted(list(zip(feature_importances[cluster].ranking_, feature_col_list)))\n",
    "    ordered_feautures.append(list(zip(*elements))[1])\n",
    "ordered_feautures_df = pd.DataFrame(ordered_feautures,  index=clusters)\n",
    "ordered_feautures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Manually Select features\n",
    "# default select 10 most important\n",
    "selected_features = {}\n",
    "for group_key, _ in  ordered_feautures_df.iterrows():  \n",
    "    selected_features[group_key] = set(ordered_feautures_df.loc[group_key, 0:9].values)\n",
    "\n",
    "# change mannually the features\n",
    "# in this example I am adding both categorical featuresfor each category\n",
    "selected_features['A'].update(['feature_0', 'feature_1'])\n",
    "selected_features['B'].update(['feature_0', 'feature_1'])\n",
    "selected_features['C'].update(['feature_0', 'feature_1'])\n",
    "selected_features['D'].update(['feature_0', 'feature_1'])\n",
    "# Discard features that are not going to be in the future\n",
    "# And discard features that are not important from the \"business perspective\"\n",
    "    \n",
    "# In the end selected_features; a dictionary with keys the group names and values list of features that are going to be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually identify which categorical features are nominal and which are ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g1</td>\n",
       "      <td>g2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>g2</td>\n",
       "      <td>g2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>g2</td>\n",
       "      <td>g2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>g2</td>\n",
       "      <td>g2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>g2</td>\n",
       "      <td>g3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1 feature_0\n",
       "6         g1        g2\n",
       "10        g2        g2\n",
       "81        g2        g2\n",
       "83        g2        g2\n",
       "92        g2        g3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check each group seperately and add in the bellow two lists which features are ordilan and which are nominal\n",
    "group1 = train_x[train_x[cat_feature] == clusters[0]][selected_features[clusters[0]]]\n",
    "group1[list(get_categorical_features(group1))].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['feature_1']\n",
    "nominal_features = ['feature_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# space can be different for each group but let this for the future if it is needed\n",
    "space={\n",
    "    'n_estimators' : hp.choice('n_estimators', np.arange(10, 150, 20, dtype=int)),\n",
    "    'max_depth': hp.choice('max_depth', np.arange(1, 3, dtype = int)),\n",
    "    'subsample': hp.quniform('subsample', 0.5, 0.7, 0.05),\n",
    "    'min_child_weight': hp.quniform ('min_child_weight', 1, 20, 1),\n",
    "    'gamma' : hp.quniform('gamma', 0.7, 1, 0.05),\n",
    "    'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 0.7, 0.05), \n",
    "    'learning_rate' : hp.quniform('learning_rate', 0.001, 0.1, 0.01), \n",
    "    'transformer_nominal': hp.choice('transformer_nominal', ['TargetEncoder', 'JamesSteinEncoder']),\n",
    "    'transformer_ordinal': hp.choice('transformer_ordinal', ['OneHotEncoder', 'OrdinalEncoder'])\n",
    "}\n",
    "\n",
    "def score(params):\n",
    "    num_round = int(params['n_estimators'])\n",
    "    del params['n_estimators']\n",
    "    # preprocessing\n",
    "    categorical_features = get_categorical_features(data=x_group)\n",
    "    \n",
    "    # preprocess nominals\n",
    "    transformer_nominal = get_transformer(params['transformer_nominal'])\n",
    "    gp_nominals = [feature for feature in categorical_features if feature in nominal_features]\n",
    "    transformer_nominal.cols = gp_nominals\n",
    "    \n",
    "    # preprocess ordinals\n",
    "    transformer_ordinal = get_transformer(params['transformer_ordinal'])\n",
    "    gp_ordinal = [feature for feature in categorical_features if feature in ordinal_features]\n",
    "    transformer_ordinal.cols = gp_ordinal\n",
    "    \n",
    "    gbm_model = xgboost.XGBRegressor(n_estimators = num_round, \n",
    "                                     objective = partial(squared_error_objective_with_weighting, under_predict_weight=2.0), \n",
    "                                     max_depth = params['max_depth'],\n",
    "                                     subsample = params['subsample'],\n",
    "                                     min_child_weight = params['min_child_weight'],\n",
    "                                     gamma = params['gamma'],\n",
    "                                     colsample_bytree = params['colsample_bytree'],\n",
    "                                     learning_rate = params['learning_rate'],\n",
    "                                     n_jobs = 8,\n",
    "                                     seed = 1234,\n",
    "                                     silent=True)\n",
    "    \n",
    "    pipeline = Pipeline([('transformer_ordinal', transformer_ordinal), \n",
    "                         ('transformer_nominal', transformer_nominal), \n",
    "                         ('estimator', gbm_model)])\n",
    "\n",
    "    score = cross_val_score(pipeline, x_group, y_group, cv=KFold(n_splits=10, random_state=9876), \n",
    "                            scoring='neg_mean_squared_error')\n",
    "    loss = np.abs(np.mean(score))\n",
    "    return {'loss' : loss, 'status' : STATUS_OK}\n",
    "\n",
    "\n",
    "def optimize(space, x_group, y_group, gp_key):\n",
    "    trials = Trials()\n",
    "    best = fmin(fn=score, \n",
    "                space=space, \n",
    "                algo=tpe.suggest, \n",
    "                max_evals=20,\n",
    "                trials=trials\n",
    "               )\n",
    "    return space_eval(space, best), trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking A ...\n",
      "100%|██████████| 20/20 [00:21<00:00,  1.08s/trial, best loss: 6873.547324469885]\n",
      "Checking B ...\n",
      "100%|██████████| 20/20 [00:43<00:00,  2.18s/trial, best loss: 9385.307973852461] \n",
      "Checking C ...\n",
      "100%|██████████| 20/20 [00:23<00:00,  1.18s/trial, best loss: 4954.1840644192725]\n",
      "Checking D ...\n",
      "100%|██████████| 20/20 [00:29<00:00,  1.46s/trial, best loss: 24768.691316215692]\n"
     ]
    }
   ],
   "source": [
    "groups = train_x.groupby(cat_feature)\n",
    "params = {}\n",
    "for gp_key, group in groups:\n",
    "    print('Checking ' + gp_key + ' ...')\n",
    "    # keep only the most improtant features\n",
    "    x_group = group[selected_features[gp_key]]\n",
    "    y_group = train_y[x_group.index]\n",
    "    # find best parameters for each model-group\n",
    "    best_params, trials = optimize(space, x_group, y_group, gp_key)\n",
    "    params[gp_key] = best_params\n",
    "    \n",
    "# in the end we keep params; a dictionary with keys the group names and values dictionaries of the selected hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for A trained\n",
      "Model for B trained\n",
      "Model for C trained\n",
      "Model for D trained\n"
     ]
    }
   ],
   "source": [
    "# Initiliaze model\n",
    "model = MultiModel(group_col=cat_feature, clusters=clusters, params=params,\n",
    "                   selected_features=selected_features, nominals=nominal_features, ordinals=ordinal_features)\n",
    "model.fit(train_x, train_y)\n",
    "pred_train_y = model.predict(train_x)\n",
    "pred_test_y = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train performance 0.96\n",
      "Validation performance 0.52\n"
     ]
    }
   ],
   "source": [
    "print('Train performance {}'.format(round(r2_score(train_y, pred_train_y), 2)))\n",
    "print('Validation performance {}'.format(round(r2_score(test_y, pred_test_y), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Train final model and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with the whole dataset! \n",
    "# Initiliaze model\n",
    "# combine into one dataset\n",
    "total_x = pd.concat([train_x, test_x], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "total_y = pd.concat([train_y, test_y], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "del train_x, train_y, test_x, test_y\n",
    "\n",
    "# Initiliaze model\n",
    "model = MultiModel(group_col=cat_feature, clusters=clusters, params=params,\n",
    "                   selected_features=selected_features, nominals=nominal_features, ordinals=ordinal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: must use one_hot_encode=False to prevent one-hot encoding of categorical features in input data\n",
    "prediction_model = PredictionModel(\"multi_model\", path='./exported_models', one_hot_encode=False)\n",
    "prediction_model.model = model\n",
    "# save feature names (no strictly since all the preprocessing is made being made in the pipeline)\n",
    "prediction_model.features = {key: [] for key in total_x.columns}\n",
    "prediction_model.target = {target: []}\n",
    "\n",
    "prediction_model.ordered_column_list = sorted(total_x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for A trained\n",
      "Model for B trained\n",
      "Model for C trained\n",
      "Model for D trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiModel(clusters=array(['A', 'B', 'C', 'D'], dtype=object),\n",
       "           group_col='category', nominals=['feature_0'], ordinals=['feature_1'],\n",
       "           params={'A': {'colsample_bytree': 0.65, 'gamma': 0.75,\n",
       "                         'learning_rate': 0.07, 'max_depth': 1,\n",
       "                         'min_child_weight': 2.0, 'n_estimators': 70,\n",
       "                         'subsample': 0.65,\n",
       "                         'transformer_nominal': 'TargetEncoder',\n",
       "                         'transformer_ordinal': 'OrdinalEncoder'},\n",
       "                   'B':...\n",
       "                                    'feature_16', 'feature_17', 'feature_19',\n",
       "                                    'feature_2', 'feature_6', 'feature_7'},\n",
       "                              'C': {'feature_0', 'feature_1', 'feature_12',\n",
       "                                    'feature_13', 'feature_15', 'feature_16',\n",
       "                                    'feature_17', 'feature_18', 'feature_3',\n",
       "                                    'feature_4', 'feature_6', 'feature_8'},\n",
       "                              'D': {'feature_0', 'feature_1', 'feature_10',\n",
       "                                    'feature_13', 'feature_14', 'feature_17',\n",
       "                                    'feature_18', 'feature_3', 'feature_4',\n",
       "                                    'feature_5', 'feature_8', 'feature_9'}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_model.model.fit(total_x, total_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python36] *",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
