{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyceCREAM example\n",
    "\n",
    "Here is a short example on using pycecream. I briefly cover generating synthetic data and calling a new pycecream object to ingest and fit the accretion disc model (or emission line model) to a set of input light curves. I also demonstrate how to access the output of the pycecream fit. The output includes the fitted light curves, any new light curve data points after merging, fitted response functions and parameter MCMC chain histories for the disc and/or tophat response parameters.\n",
    "\n",
    "Most of these features are used in some form or another from a previous f90 version of this code (CREAM) in the following literature\n",
    "\n",
    "Grier et al in prep\n",
    "Grier et al 2018    https://iopscience.iop.org/article/10.3847/1538-4357/aa98dc/pdf\n",
    "Starkey et al 2017  https://ui.adsabs.harvard.edu/#abs/arXiv:1611.06051\n",
    "Starkey et al 2016  https://ui.adsabs.harvard.edu/#abs/arXiv:1511.06162\n",
    "\n",
    "Please send questions to ds207@st-andrews.ac.uk. Though I am currently taking a break from academia and may take some time to respond, I will try to do so as soon as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Section 1: Generate Synthetic Light Curves\n",
    "\n",
    "In this example we generate 4 disk light curves and 2 emission-line light curves modelled as a top-hat with a 20-day lag. The code below generates a list where each index contains an Nx3 numpy array for each light curve. The 3 vertical axis for each light curve are the time, flux and noise respectively (query synthetic_data['echo lightcurves'][0] for an example of the format required when inputting your own light curve data).\n",
    "\n",
    "The example below combines continuum and line light curves and illustrates a case in which you may have two of the same emission line (and so want to fit with the same response function model) but observed from different telescopes that require seperate noise models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy_stark.myfake as mf\n",
    "\n",
    "synthetic_data = mf.myfake(\n",
    "    '''enter the wavelengths (-1 indicates an emission line light curve modelled with a top-hat response)'''\n",
    "    [4000.0,5000.0,5000.0,7000.0,-1.0,-1.0],\n",
    "    \n",
    "    '''set the signal-to-noise relative to light curve rms'''\n",
    "    [50.0,50.0,10.0,50.0,50,10.],\n",
    "    \n",
    "    '''set the mean cadence'''\n",
    "    [1.0,1.0,2.0,1.0,1.0,3.0],\n",
    "    \n",
    "    '''\n",
    "    set the centroid for the top-hat (I think thats what this does but the line lag \n",
    "    thing is still newish so Im used to just making continuum light curve)\n",
    "    '''\n",
    "    thcent = 20.0\n",
    ")\n",
    "\n",
    "'''This recovers the synthetic data'''\n",
    "dat = synthetic_data['echo light curves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycecream"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
